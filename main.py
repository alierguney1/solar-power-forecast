# -*- coding: utf-8 -*-
"""bitirme.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SE_XARvut6vkSU_I9K3pLkz3MbJR4no9
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.models import load_model

# Maximum Capacity of the Solar Farm
MAX_CAPACITY = int(30)

# Load data
df = pd.read_csv('data.csv') 
df.columns = [
    'time',
    'tsi',
    'dni',
    'ghi',
    'temp',
    'atm',
    'rh',
    'power'
]

"""
new_column_names = {
    'Time(year-month-day h:m:s)': 'time',
    'Total solar irradiance (W/m2)': 'tsi',
    'Direct normal irradiance (W/m2)': 'dni',
    'Global horizontal irradiance (W/m2)': 'ghi',
    'Air temperature  (Â°C)': 'temp',
    'Atmosphere (hpa)': 'atm',
    'Relative humidity (%)': 'rh',
    'Power (MW)': 'power'
}
"""

cols = df.columns[1:]

# Convert all columns except the first one to float
for col in cols:
    df[col] = pd.to_numeric(df[col], errors='coerce') 

# Convert to datetime object
df['time'] = pd.to_datetime(df['time'])
# Normalize power by dividing to the MAX_CAPACITY
df['power'] = df['power']/ MAX_CAPACITY
df.set_index('time', inplace=True)
print(df.describe())
print(df.head())
df.info()



#df.fillna(method="ffill")

print(df.head())
df_1day = df.head(96)
df_1day

a1_list = []
for i in range(1,96):

    abcd = df['power'][i::96]
    a1 = (abcd.sum()) / int(len(abcd))
   
    a1_list.append(a1)
a1_list 

fig, ax = plt.subplots(figsize=(10, 6))
print(df.index.hour[1:96:1]+df.index.minute[1:96:1])
ax.plot(df.index[1:96:1], a1_list)

plt.show()

#df_1day.set_index('time', inplace=True)

# Create a line chart
fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(df_1day.index, df_1day['tsi'], label='TSI')
ax.plot(df_1day.index, df_1day['dni'], label='DNI')
ax.plot(df_1day.index, df_1day['ghi'], label='GHI')
ax.plot(df_1day.index, df_1day['atm'], label='atm')
ax.plot(df_1day.index, df_1day['rh'], label='rh')
ax.plot(df_1day.index, df_1day['power'], label='power')
ax.set_xlabel('Time')
ax.set_ylabel('Irradiance (W/m2)')
ax.set_title('Solar Irradiance')
ax.legend()

# Save the chart to a file
plt.savefig('solar_irradiance.png')

import matplotlib.ticker as ticker
df["tsi"].value_counts()

fig, ax = plt.subplots(figsize=(10, 6))
#dfHours["Hour"] = dfHours.index.hour()
#plt.hist(dfHours["power"])

hours = df.index.hour
print(hours)
dfHours = df.copy()
dfHours["Hour"] = hours
#  the chart
'''plt.bar(dfHours["Hour"],dfHours["power"])
tick_spacing = 1
ax.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))
plt.show()'''

# Feature correlation for all features
plt.figure(figsize=(7, 7))
sns.heatmap(df.corr(), cmap='Reds', annot=True)
plt.title('Feature correlation');

# Create training data set with a certain LAG for training the model

df_temp1 = df.copy()
df_temp1.reset_index(drop=True, inplace=True)  # Reset the index of df_temp1

LAG = 3

inputs = []
outputs = []
for i in range(len(df_temp1["power"])-10):
    deneme_list = []
    for j in range(LAG):
        deneme_list.append(df_temp1.loc[(i-j)+LAG-1, :].values.flatten().tolist())
    inputs.append(list(np.concatenate(deneme_list).flat))
    outputs.append(df_temp1["power"][i])

print(df_temp1.head(10))
print(outputs)
inputs

# train test
from sklearn.model_selection import train_test_split
X = inputs
y = outputs
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, shuffle = False)
print(X_train[1:5:1])

# Scaling

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
X_train
X_test

'''
# Model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dense(units=1))

model.summary()

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])

# Fit the model
#model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

# Evaluate the model
loss, mse = model.evaluate(X_test, y_test)
print('Mean squared error: ', mse)

# Make predictions
y_pred = model.predict(X_test)
'''
'''
# Visualize the predictions
plt.plot(y_test, color='blue', label='Actual Power')
plt.plot(y_pred, color='red', label='Predicted Power')
plt.title('Power Prediction')
plt.xlabel('Time')
plt.ylabel('Power')
plt.legend()
plt.show()
'''
plt.plot(y_test[1:100], color='blue', label='Actual Power')
#plt.plot(y_pred, color='red', label='Predicted Power')
plt.title('Power Prediction')
plt.xlabel('Time')
plt.ylabel('Power')
plt.legend()
plt.show()

# Preprocessing
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(inputs)
scaled_data

# Define input and output variables
#features = ['TSI', 'DNI', 'GHI', 'Temperature', 'Atmosphere', 'Humidity']
#target = 'Power'


'''

# Split into train and test sets
train_size = int(len(scaled_data) * 0.7)
train_data = scaled_data[:train_size, :]
test_data = scaled_data[train_size:, :]

# Create function to create LSTM model
def create_model(train_data):
    x_train = []
    y_train = []
    for i in range(60, len(train_data)):
        x_train.append(train_data[i-60:i, :-1])
        y_train.append(train_data[i, -1])
    x_train, y_train = np.array(x_train), np.array(y_train)

    # Reshape input data to be 3D
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], len(features)))

    # Create LSTM model
    model = Sequential()
    model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], len(features))))
    model.add(LSTM(units=50))
    model.add(Dense(units=1))

    # Compile model
    model.compile(optimizer='adam', loss='mean_squared_error')

    # Train model
    model.fit(x_train, y_train, epochs=10, batch_size=32)

    return model

# Create LSTM model
model = create_model(train_data)

# Forecast test data
inputs = scaled_data[len(scaled_data) - len(test_data) - 60:]
x_test = []
for i in range(60, inputs.shape[0]):
    x_test.append(inputs[i-60:i, :-1])
x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], len(features)))
predicted_values = model.predict(x_test)
predicted_values = scaler.inverse_transform(predicted_values)

# Plot results
import matplotlib.pyplot as plt
plt.plot(data[target].values[train_size + 60:], color='blue', label='Actual')
plt.plot(predicted_values, color='red', label='Predicted')
plt.legend()
plt.show()
'''
print(scaled_data[50])
print(inputs[50])
print(outputs[50])

print(X_train[50])
print(y_train[50])

